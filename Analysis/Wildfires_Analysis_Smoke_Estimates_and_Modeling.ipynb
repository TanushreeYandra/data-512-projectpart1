{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2893073",
   "metadata": {},
   "source": [
    "# DATA 512 - Project Part 1: Common Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb4824",
   "metadata": {},
   "source": [
    "## Wildfires Analysis - Creation of a Smoke Estimate and its Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e449b489",
   "metadata": {},
   "source": [
    "### Tanushree Yandra, University of Washington, Seattle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3c60e3",
   "metadata": {},
   "source": [
    "More and more frequently, summers in the western US have been characterized by wildfires with smoke billowing across multiple western states. There are many proposed causes for this: climate change, US Forestry policy, growing awareness, just to name a few. Regardless of the cause, the impact of wildland fires is widespread. There is a growing body of work pointing to the negative impacts of smoke on health, tourism, property, and other aspects of society. This project analyzes wildfire impacts on the city of Twin Falls, Idaho in the US. The end goal is to be able to inform policy makers, city managers, city councils, or other civic institutions, to make an informed plan for how they could or whether they should make plans to mitigate future impacts from wildfires.\n",
    "\n",
    "Wildland fires within 1250 miles of Twin Falls, Idaho are analyzed for the last 60 years (1963-2020). This section of the notebook uses the [Processed Wildfires Dataset]() generated from the [Wildfire Analysis - Data Preprocessing notebook](), and the [Yearly AQI Data]() generated from the [Wildfire Analysis - Data Retrieval notebook](). Using these datasets, a smoke estimate is created which is then evaluated using the AQI levels. The smoke estimate is then modeled to generate predictions from 2021 to 2049. Some visualizations are also created at the end to generate further insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88a041",
   "metadata": {},
   "source": [
    "### Step 1: Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055ee34",
   "metadata": {},
   "source": [
    "First, we start by importing required packages and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bf49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are standard python modules\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# The modules below are not standard Python modules\n",
    "# You will need to install these with pip/pip3 if you do not already have it\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a5735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the warning statements\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d6d9c2",
   "metadata": {},
   "source": [
    "### Step 2: Read the Processed Wildfires Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f88e4",
   "metadata": {},
   "source": [
    "We will now load the processed wildfires data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87edf8bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Wildfire_Data_Processed.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the CSV data into a dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m wf_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWildfire_Data_Processed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Wildfire_Data_Processed.csv'"
     ]
    }
   ],
   "source": [
    "# Read the CSV data into a dataframe\n",
    "wf_df = pd.read_csv('Wildfire_Data_Processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top of the dataframe\n",
    "wf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0691536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the shape of the dataframe\n",
    "wf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ca902",
   "metadata": {},
   "source": [
    "Our wildfires data has 72608 instances of wildfires with 9 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca91ac",
   "metadata": {},
   "source": [
    "### Step 3: Creating a Smoke Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dce3e01",
   "metadata": {},
   "source": [
    "Now, we need to create an annual estimate of wildfire smoke in Twin Falls, Idaho. This estimate is just a number that we will eventually use to build a predictive model. It seems reasonable that a large fire burning a large number of acres, and that is close to our city would put more smoke into a city than a small fire that is much further away. We will thus use the variables 'GIS_Acres' and 'Distance' to define our smoke estimate and then apply it to every fire within 1250 miles of our city between 1963 and 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c330cf1",
   "metadata": {},
   "source": [
    "Before that, we need to make the two variables consistent in terms of their units. This is done by converting the 'GIS_Acres' variable to square miles since the 'Distance' values are stored as miles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d80ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'GIS_Acres' to square miles and store the values in a new column 'GIS_Square_Miles'\n",
    "wf_df['GIS_Square_Miles'] = wf_df['GIS_Acres']*0.0015625"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824ecf7",
   "metadata": {},
   "source": [
    "Now, we will plot the two variables to understand their inherent relationship. This will help us create our smoke estimate accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa74465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting 'Distance' and 'GIS_Square_Miles'\n",
    "plt.scatter(wf_df['Distance'], wf_df['GIS_Square_Miles'])\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Distance from Twin Falls, Idaho (Miles)')\n",
    "plt.ylabel('Wildfire Area (Square Miles)')\n",
    "plt.title('Understanding the Relationship between Distance of the Wildfire from Twin Falls, Idaho, and its Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b668f1",
   "metadata": {},
   "source": [
    "The relationship in the above plot looks pretty random where most of the wildfires are concetrated in smaller areas region. There is no apparent relationship visible.\n",
    "\n",
    "Let's try plotting the square of the 'Distance' with the 'GIS_Square_Miles' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a601d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the square of the distance and store it in a new column called 'Distance_Square'\n",
    "wf_df['Distance_Square'] = (wf_df['Distance'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting 'Distance_Square' and 'GIS_Square_Miles'\n",
    "plt.scatter(wf_df['Distance_Square'], wf_df['GIS_Square_Miles'])\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Squared Distance (Square Miles)')\n",
    "plt.ylabel('Wildfire Area (Square Miles)')\n",
    "plt.title('Understanding the Relationship between the Square of the Distance of the Wildfire, and its Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a18ffd",
   "metadata": {},
   "source": [
    "There seems to be some improvement in the manner in which the points are scattered. It can be observed that the data points that whose square of distance is smaller, tend to have a higher area. The relationship can be approximated to a decaying exponential function.\n",
    "\n",
    "Thus, the smoke estimate that best captures our intuition can be created using the following formula,\n",
    "\n",
    "*Smoke Estimate = w1 x Area of Fire x exp(-w2 x Distance^2)*\n",
    "\n",
    "The aim is to not have a very high smoke estimate value. The intention is to keep it under 50. Based on the existing data points, w1 and w2 were chosen in such a way that the overall smoke estimate value stays under 50. Thus w1 and w2 for this analysis were chosen only to keep the number of digits of 'Distance_Square' and 'Area' under control.\n",
    "\n",
    "Since 'GIS_Square_Miles' is usually in hundreds, w1 is chosen as 1/100 to reduce the overall value of smoke estimate. Similarly, since 'Distance_Square' is a very high value usually in hundred thousands, w2 is chosen as 1/100000 to curb the digits. Thus, the final smoke estimate looks as follows,\n",
    "\n",
    "*Smoke Estimate = (Area of Fire x exp(Distance^2/100000))/100*\n",
    "\n",
    "Using the above formula, smoke estimate is calculated for every fire in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a9ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Smoke Estimate for every fire in the dataset\n",
    "wf_df['Smoke_Estimate'] = wf_df['GIS_Square_Miles']*np.exp(-wf_df['Distance_Square']/100000)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2f60a3",
   "metadata": {},
   "source": [
    "### Step 4: Analyzing the Smoke Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc41e0",
   "metadata": {},
   "source": [
    "The next step is to understand how the smoke estimate for each fire will be used to find one smoke estimate for eevry year. This can be done by taking the cumulative of smoke estimate during each year or by amortizing over the fire season (May 1st to October 31st).\n",
    "\n",
    "To make this decision, the total number of wildfires were plotted for every year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba04e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by the fire year and find the total number of wildfires for each year\n",
    "count_by_year = wf_df.groupby(['Fire_Year'])['USGS_Assigned_ID'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e032aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total number of wildfires against the fire year\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(count_by_year['Fire_Year'], count_by_year['USGS_Assigned_ID'])\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Fire Year')\n",
    "plt.ylabel('Total Number of Wildfires')\n",
    "plt.title('Analyzing the Total Number of Wildfires every Year')\n",
    "plt.xlim([1960, 2023]) \n",
    "plt.xticks(np.arange(1960, 2023, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e19418",
   "metadata": {},
   "source": [
    "It can be seen that the total number of wildfires have increased over time. This change has been quite significant from 1963 to 2020. This could also be attributed to the lack of proper reporting measure earlier, but either way, taking an average of the smoke estimate would not account for the total number of wildfires. Since we are analyzing the \"smoke emitted\", it would make more sense if we take a cumulative of the smoke estimate. This will take the large number of wildfires in recent times into account.\n",
    "\n",
    "So we now find the Cumulative Smoke Estimate for every year and save it to a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe that has yearly data and the cumulative smoke estimate values\n",
    "smoke_by_year = wf_df.groupby(['Fire_Year'])['Smoke_Estimate'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative smoke estimate with the fire year\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(smoke_by_year['Fire_Year'], smoke_by_year['Smoke_Estimate'])\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Fire Year')\n",
    "plt.ylabel('Cumulative Smoke Estimate')\n",
    "plt.title('Analyzing the Yearly Cumulative Smoke Estimate from 1963 to 2020')\n",
    "plt.xlim([1960, 2023]) \n",
    "plt.xticks(np.arange(1960, 2023, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0d7df",
   "metadata": {},
   "source": [
    "From the plot above, there seems to be some sort of periodicity existing. The smoke estimate goes up at a peak every 3-5 years. The size of the peaks is also increasing upto the year 2007 after which the peaks have gone down slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44169fb",
   "metadata": {},
   "source": [
    "### Step 5: Evaluating the Smoke Estimate's Performance Using US EPA Air Quality Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8fe41",
   "metadata": {},
   "source": [
    "The next step is trying to understand how good or bad our smoke estimate might be. Now that we have developed our smoke estimate, we will compare our estimate to the AQI (Air Quality Index) data from the US EPA. This data was retrieved from the API in the Data Retrieval notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the AQI data from a CSV file to a dataframe\n",
    "aqi_df = pd.read_csv('Yearly_AQI_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a675df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative smoke estimate and the maximum AQI data for every year\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(smoke_by_year['Fire_Year'], smoke_by_year['Smoke_Estimate'], label='Cumulative Smoke Estimate')\n",
    "plt.plot(aqi_df['Year'], aqi_df['AQI'], label='Maximum AQI')\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Fire Year')\n",
    "plt.ylabel('Cumulative Smoke Estimate/AQI')\n",
    "plt.title('Analyzing any Underlying Relationship between the Yearly Cumulative Smoke Estimate \\n\\\n",
    "and the Maximum AQI Data for the Fire Season')\n",
    "plt.xlim([1960, 2023]) \n",
    "plt.xticks(np.arange(1960, 2023, 5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3287b",
   "metadata": {},
   "source": [
    "As evident from the above plot, the Maximum AQI data for the fire season of every year is missing for the years 1963-1985. However, for the years where the data is available, there seems to be a somewhat dependent relationship between the two variables - Cumulative Smoke Estimate and the Maximum AQI. The peaks and dips are mostly in sync for both the curves. However, there are a few instances where these don't match.\n",
    "\n",
    "The AQI measures air pollution levels, which can arise from various sources, not solely wildfires. While wildfires are a significant contributor to poor air quality and can substantially impact the AQI, other factors and sources also influence air pollution levels. Some of these other sources are industrial emissions, vehicle emissions, construction activities, etc. Thus, while there might be a relationship between both the variables we cannot assume that wildfires are the sole reason for poor AQI.\n",
    "\n",
    "Overall, the curves are quite smilar in their trends indicating that our smoke estimate is capturing the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfc1fc",
   "metadata": {},
   "source": [
    "### Step 6: Modeling the Smoke Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd64aa0",
   "metadata": {},
   "source": [
    "The plot of the Cumulative Smoke Estimate shows continous peaks and falls which are difficult to capture using a regression model. The moving average model, often used to predict stock prices that are quite volatile, can be used in this case to model the Smoke Estimate data.\n",
    "\n",
    "The AQI data can also be added as a feature in this model. However, since the AQI data is missing for more than 20 years, we will only use the smoke estimate to compute the rolling average. The model that will be used for this analysis is Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX) model.\n",
    "\n",
    "For the model to be applied, the date column needs to be set as the index of the dataframe. It also needs to be changed to the pandas datetime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89690389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe containing yearly cumulative smoke estimate data\n",
    "sarimax_df = smoke_by_year.copy()\n",
    "\n",
    "# Convert the year column to datetime and save it as a new column called 'date'\n",
    "sarimax_df['date'] = pd.to_datetime(sarimax_df['Fire_Year'], errors='ignore', format='%Y')\n",
    "\n",
    "# Set the above date column as the dataframe's index\n",
    "sarimax_df = sarimax_df.set_index('date')\n",
    "\n",
    "# Change the index to datetime object and convert into the type 'datetime64[ns]'\n",
    "# It is important to convert it to the type 'datetime64[ns]' because the default type is numpy datetime\n",
    "# A datetime format other than 'datetime64[ns]' throws an error while training the model\n",
    "sarimax_df.index = pd.to_datetime(sarimax_df.index).astype('datetime64[ns]')\n",
    "\n",
    "# We then drop the 'Fire_Year' column as it is no longer needed\n",
    "sarimax_df.drop(['Fire_Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d869c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top of the dataframe\n",
    "sarimax_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6b05c",
   "metadata": {},
   "source": [
    "Now that we have prepared our dataset for the model, we can go ahead and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a SARIMAX model\n",
    "# Set the order and season_order parameters as per your requirements\n",
    "# The fourth coordinate of the seasonal_order parameter is set to 12 for yearly data\n",
    "model = sm.tsa.SARIMAX(sarimax_df['Smoke_Estimate'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "results = model.fit()\n",
    "\n",
    "# Generate a list of years for our range of 1963 to 2020\n",
    "years_range = np.arange(1963, 2021, 1)\n",
    "\n",
    "# Create a datetime index with the type 'datetime64[ns]'\n",
    "future_index = pd.to_datetime(years_range, format='%Y').astype('datetime64[ns]')\n",
    "\n",
    "# Generate predictions using the start date, end date and the time-series index\n",
    "forecast = results.get_prediction(start=future_index[0], end=future_index[-1], exog=sarimax_df.index)\n",
    "\n",
    "# Extract the predicted mean values for the years 1963 to 2020\n",
    "Y_pred = list(forecast.predicted_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7dc4fe",
   "metadata": {},
   "source": [
    "Now we plot the original data and the fitted model to understand the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original data with the fitted model\n",
    "X = list(smoke_by_year['Fire_Year'])\n",
    "Y = list(smoke_by_year['Smoke_Estimate'])\n",
    "\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(X, Y, label='Original Cumulative Smoke Estimate')\n",
    "\n",
    "# Plot the fitted model line\n",
    "plt.plot(X, Y_pred, 'r-', label='Fitted Model')\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Analyzing the Fitted SARIMAX model against the Original Data for the years 1963-2020')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d15a40",
   "metadata": {},
   "source": [
    "The model does not fully capture the data for the current period, and there is quite some scope for improvement. However, we also do not want to overfit the data. We will go ahead with this model and generate predictions for the smoke estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc84246",
   "metadata": {},
   "source": [
    "### Step 7: Generating Predictions for the Years 2021-2049"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7c253",
   "metadata": {},
   "source": [
    "We will now use the trained model above to predict smoke estimates for every year for the next 29 years (i.e., 2021-2049). While we are currently in the year 2023, predictions are being generated from 2021 onwards since the Smoke Estimate data is available until 2020 only. We will also make sure to convey appropriate levels of uncertainty in our predictions.\n",
    "\n",
    "The first step thus will be to generate predictions and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of years for our range of 2021 to 2049\n",
    "years_range = np.arange(2021, 2050, 1)\n",
    "\n",
    "# Create a datetime index with the type 'datetime64[ns]'\n",
    "future_index = pd.to_datetime(years_range, format='%Y').astype('datetime64[ns]')\n",
    "\n",
    "# Generate predictions using the start date, end date and the time-series index\n",
    "forecast = results.get_prediction(start=future_index[0], end=future_index[-1], exog=sarimax_df.index)\n",
    "\n",
    "# Extract the predicted mean values for the years 2021 to 2049 and their confidence intervals\n",
    "forecast_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338785ea",
   "metadata": {},
   "source": [
    "Now we will plot our predictions with their uncertainty along with the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual data\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(X, Y, label='Original Cumulative Smoke Estimate')\n",
    "\n",
    "# Plot the predicted values\n",
    "plt.plot(years_range, forecast_values, color='red', label='Predicted Cumulative Smoke Estimate Values')\n",
    "\n",
    "# Plot the confidence intervals\n",
    "plt.fill_between(\n",
    "    years_range,\n",
    "    list(confidence_intervals.iloc[:, 0]),\n",
    "    list(confidence_intervals.iloc[:, 1]),\n",
    "    color='red', alpha=0.1, label='Uncertainty'\n",
    ")\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Predicted Cumulative Smoke Estimates for the years 2021-2049 with Confidence Intervals\\n\\\n",
    "Against the Original Cumulative Smoke Estimates')\n",
    "plt.xlabel('Fire Year')\n",
    "plt.ylabel('Cumulative Smoke Estimate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f7c9a",
   "metadata": {},
   "source": [
    "The predictions look quite reasonable where the 3-5 years periodic frequency of peaks and dips is maintained. The height of the peaks alternatively goes up and down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e3e0d",
   "metadata": {},
   "source": [
    "### Step 8: Creating Final Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c46b2c7",
   "metadata": {},
   "source": [
    "We will now illustrate the work of our analysis with a few time series graphs. The wildfire data is annual, so our time series will be on an annual basis. All the time series will cover the analysis range for the years 1963-2020, but not the prediction range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da3ec4",
   "metadata": {},
   "source": [
    "**1. Distribution of Wildfires by their Distance from Twin Falls, Idaho**\n",
    "\n",
    "We will produce a histogram showing the number of fires occurring every 50 mile distance from Twin Falls, Idaho up to 1250 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2892d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of wildfires by their distance from Twin Falls, Idaho\n",
    "plt.figure(figsize=(11, 6))\n",
    "bins = np.arange(0, 1250, 50)\n",
    "plt.hist(wf_df['Distance'], bins=bins, edgecolor='black')\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Distance from Twin Falls, Idaho (Miles)')\n",
    "plt.ylabel('Total Number of Wildfires')\n",
    "plt.title('Distribution of Wildfires by their Distance from Twin Falls, Idaho')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04605374",
   "metadata": {},
   "source": [
    "It can be observed that the most number of wildfires occur around the 400-450 miles radius of Twin Falls, Idaho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e3253",
   "metadata": {},
   "source": [
    "**2. Total Acres Burned by Year**\n",
    "\n",
    "We will produce a time series graph of total acres burned per year for the fires occurring within 1250 miles of Twin Falls, Idaho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255aca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by year and calculate the total burnt acres\n",
    "acres_by_year = wf_df.groupby(['Fire_Year'])['GIS_Acres'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9793fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the total acres burnt every year\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(acres_by_year['Fire_Year'], acres_by_year['GIS_Acres'])\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Fire Year')\n",
    "plt.ylabel('Total Acres Burned')\n",
    "plt.title('Total Acres Burned by Wildfires every Year')\n",
    "plt.xlim([1960, 2023]) \n",
    "plt.xticks(np.arange(1960, 2023, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689f228",
   "metadata": {},
   "source": [
    "The total acres burned by wildfires has a lot of peake and dips. Overall, the height of the peaks is steadily increasing indicating that more and more acreage is burned over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee38fc9",
   "metadata": {},
   "source": [
    "**3. Time Series Containing Fire Smoke Estimate and the AQI Estimate**\n",
    "\n",
    "We will produce a time series graph containing our fire smoke estimate for and the AQI estimate for Twin Falls, Idaho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e847ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative smoke estimate and the maximum AQI data for every year\n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(smoke_by_year['Fire_Year'], smoke_by_year['Smoke_Estimate'], label='Cumulative Smoke Estimate')\n",
    "plt.plot(aqi_df['Year'], aqi_df['AQI'], label='Maximum AQI')\n",
    "\n",
    "# Set labels and show plot\n",
    "plt.xlabel('Fire Year')\n",
    "plt.ylabel('Cumulative Smoke Estimate/AQI')\n",
    "plt.title('Time Series Containing Fire Smoke Estimate and the AQI Estimate')\n",
    "plt.xlim([1960, 2023]) \n",
    "plt.xticks(np.arange(1960, 2023, 5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3f12c",
   "metadata": {},
   "source": [
    "As evident from the above plot, the Maximum AQI data for the fire season of every year is missing for the years 1963-1985. However, for the years where the data is available, there seems to be a somewhat dependent relationship between the two variables - Cumulative Smoke Estimate and the Maximum AQI. The peaks and dips are mostly in sync for both the curves. However, there are a few instances where these don't match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1e030",
   "metadata": {},
   "source": [
    "All the above plots have been explained in detail in the reflection of the project. Please refer that for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
